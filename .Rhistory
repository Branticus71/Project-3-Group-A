library(tidyverse)
library(caret)
library(corrplot)
install.packages("corrplot")
install.packages("corrr")
install.packages("psych")
library(tidyverse)
library(caret)
library(corrplot)
library(corrr)
library(psych)
library(rmarkdown)
df <- read_csv("./OnlineNewsPopularity.csv")
getwd()
df <- read_csv("./OnlineNewsPopularity.csv")
df <- read_csv("./OnlineNewsPopularity.csv")
#Creating a new variable for to contain data channels and removing the old one.
df <- df %>%
mutate(data_channel = if_else(
data_channel_is_bus == 1,
"Business",
if_else(
data_channel_is_entertainment == 1,
"Entertainment",
if_else(
data_channel_is_lifestyle == 1,
"Lifestyle",
if_else(
data_channel_is_socmed == 1,
"Socmed",
if_else(data_channel_is_tech == 1, "Tech", "World")))))) %>%
#Removing non-predictors and old data channel variables
select(-c(url, timedelta, data_channel_is_bus, data_channel_is_entertainment,
data_channel_is_socmed, data_channel_is_tech, data_channel_is_world,
data_channel_is_lifestyle)) %>%
#Changing shares to log(shares) for better graphing and models
mutate(log_shares = log(shares)) %>%
select(-shares) %>%
#Renaming the day variables
rename(monday = weekday_is_monday , tuesday = weekday_is_tuesday, wednesday = weekday_is_wednesday,          thursday = weekday_is_thursday, friday = weekday_is_friday, saturday = weekday_is_saturday,           sunday = weekday_is_sunday)
#Subsetting to just a single data_channel type
df_filtered <- df %>%
filter(data_channel == "Lifestyle")
#Creating the training and test datasets
index_train <- createDataPartition(df_filtered$log_shares, p = .7, list = FALSE )
df_train <- df_filtered[index_train,]
df_test <- df_filtered[-index_train,]
#Creating a data frame containing a categorical day variable for graphs
categ_day <- df_train %>%
mutate(day = if_else(
monday == 1,
"Monday",
if_else(
tuesday == 1,
"Tuesday",
if_else(
wednesday == 1,
"Wednesday",
if_else(
thursday == 1,
"Thursday",
if_else(
friday == 1,
"Friday",
if_else(saturday == 1,
"Saturday", "Sunday")))))))
#Removing variables that aren't continuous for tables and principal components
df_continuous <- df_train %>%
select(-c(monday, tuesday, wednesday, thursday,friday, saturday, sunday, is_weekend, data_channel,
n_non_stop_words))
#Box plot of log_shares by day
ggplot(categ_day, aes(x = day, y = log_shares, col = day)) +
geom_boxplot(fill="grey") +
geom_jitter() +
ylab("Log Shares") +
xlab("") +
theme(axis.text.x = element_text(angle = 45)) +
ggtitle("Boxplot for Log Shares by Day")
interest_vars <- c("num_imgs", "n_tokens_content", "n_unique_tokens", "rate_positive_words",
"rate_negative_words", "num_videos", "num_hrefs", "kw_avg_avg", "n_tokens_title", "self_reference_avg_sharess")
categ_day %>%
gather(interest_vars, key = "variables", value = "value") %>%
ggplot(aes(x = value, y = log_shares, color = day)) +
geom_jitter() +
stat_smooth(method = "lm") +
facet_wrap(~ variables, scales = "free", shrink = FALSE, ncol=2  )
#Need to limit to just predictors of interest once those are decided on
cor_train<- df_train %>%
correlate() %>%
focus(log_shares)
paged_table(cor_train)
cor_train %>%
mutate(term = factor(term, levels = term[order(log_shares)])) %>%
ggplot(aes(x = term, y = log_shares)) +
geom_bar(stat = "identity") +
ylab("Correlation with log(Shares)") +
xlab("Variable") +
theme(axis.text.x = element_text(angle = 90))
tab <-  describe(df_continuous, fast = TRUE)
#Arranging by Standard Deviation and rounding to two places
table_continuous <- tab %>%
arrange(desc(sd)) %>%
modify_if( ~is.numeric(.), ~round(.,2))
#Paged table to allow reader to peruse all variables
paged_table(table_continuous)
#Excluding shares for creating principal components
df_no_shares <- df_continuous %>%
select(-log_shares)
#Creating PC's along with center and scaling variables
PCs <- prcomp(df_no_shares, center = TRUE, scale = TRUE)
#Creating screeplots
par(mfrow = c(1,2))
plot(PCs$sdev^2/sum(PCs$sdev^2), xlab = "Principal Component",
ylab = "Proportion of Variance Explained", ylim = c(0, 1), type = 'b')
plot(cumsum(PCs$sdev^2/sum(PCs$sdev^2)), xlab = "Principal Component",
ylab = "Cum. Prop of Variance Explained", ylim = c(0, 1), type = 'b')
#Selecting only the PC's up to a 80% variance explained threshold using caret
PCs_eighty <- preProcess(df_no_shares, method = c("center","scale", "pca"), thresh = .8)
#Creating a data frame with just my PC's, day variables, and log_shares to use later as a regression
df_PC <- predict(PCs_eighty, newdata = df_no_shares)
#Monday is excluded to avoid multicollinearity
df_PC <- df_PC %>%
bind_cols(log_shares = df_continuous$log_shares,tuesday = df_train$tuesday,
wednesday = df_train$wednesday, thursday = df_train$thursday, friday = df_train$friday,
saturday = df_train$saturday, sunday = df_train$sunday)
set.seed(111)
fit_PC <- train(log_shares ~ ., data = df_PC,
method = "lm",
trControl = trainControl(method = "cv" , number = 10))
summary(fit_PC)
#Creating a test data frame from the PCs then using that to test the PC regression. RMSE reported after.
test_PC <- predict(PCs_eighty, newdata = df_test)
pred_PC <- predict(fit_PC, newdata = test_PC)
postResample(pred_PC, obs = df_test$log_shares)
#May need to add or remove variables later
forest_vars <- c("log_shares","num_imgs", "n_tokens_content", "n_unique_tokens", "rate_positive_words",
"rate_negative_words", "num_videos", "num_hrefs", "kw_avg_avg", "n_tokens_title",
"tuesday", "wednesday","thursday","friday", "saturday", "sunday", "monday")
df_forest <- df_train %>%
select(forest_vars)
set.seed(111)
fit_forest <- train(log_shares ~ ., data = df_forest, method = "treebag",
trControl = trainControl(method = "cv" , number = 10),
preProcess = c("center", "scale"),
mtry = c(1:16))
pred_forest <- predict(fit_forest, newdata = df_test)
postResample(pred_forest, df_test$log_shares)
df_summary <- trainSet %>%
select(n_tokens_title,n_tokens_content,num_hrefs,num_imgs,num_videos,n_unique_tokens, num_videos,average_token_length,num_keywords,shares)
set.seed(594)
splitSize <- sample(nrow(df), nrow(df)*0.7)
trainSet <- df[splitSize,]
testSet <- df[-splitSize,]
df_summary <- trainSet %>%
select(n_tokens_title,n_tokens_content,num_hrefs,num_imgs,num_videos,n_unique_tokens, num_videos,average_token_length,num_keywords,shares)
set.seed(594)
df_summary <- df_train %>%
select(n_tokens_title,n_tokens_content,num_hrefs,num_imgs,num_videos,n_unique_tokens, num_videos,average_token_length,num_keywords,shares)
set.seed(594)
df_summary <- df_train %>%
select(n_tokens_title,n_tokens_content,num_hrefs,num_imgs,num_videos,n_unique_tokens, num_videos,average_token_length,num_keywords)
describe(df_summary)
# Creating new Categorical Variables
df_train$videos_range <- ifelse(df_train$num_videos %in% c(0:30), "0-30",
ifelse(df_train$num_videos %in% c(31:60), "31-60",
ifelse(df_train$num_videos %in% c(61:90), "61-90","Null")))
df_train$videos_range <- ordered(as.factor(df_train$videos_range),
levels = c("0-30","31-60","61-90"))
df_train$day <- ifelse(df_train$weekday_is_monday == 1, "Monday",
ifelse(df_train$weekday_is_tuesday == 1, "Tuesday",
ifelse(df_train$weekday_is_wednesday == 1, "Wednesday",
ifelse(df_train$weekday_is_thursday == 1, "Thursday",
ifelse(df_train$weekday_is_friday == 1, "Friday",
ifelse(df_train$weekday_is_saturday == 1, "Saturday",
ifelse(df_train$weekday_is_sunday == 1, "Sunday","Null")))))))
# Creating new Categorical Variables
df_train$videos_range <- ifelse(df_train$num_videos %in% c(0:30), "0-30",
ifelse(df_train$num_videos %in% c(31:60), "31-60",
ifelse(df_train$num_videos %in% c(61:90), "61-90","Null")))
df_train$videos_range <- ordered(as.factor(df_train$videos_range),
levels = c("0-30","31-60","61-90"))
df_train$day <- ifelse(df_train$monday == 1, "Monday",
ifelse(df_train$tuesday == 1, "Tuesday",
ifelse(df_train$wednesday == 1, "Wednesday",
ifelse(df_train$thursday == 1, "Thursday",
ifelse(df_train$friday == 1, "Friday",
ifelse(df_train$saturday == 1, "Saturday",
ifelse(df_train$sunday == 1, "Sunday","Null")))))))
df_train$day <- ordered(as.factor(df_train$day),
levels = c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"))
contingency_table <- table(df_train$day,trainSet$videos_range)
# Creating new Categorical Variables
df_train$videos_range <- ifelse(df_train$num_videos %in% c(0:30), "0-30",
ifelse(df_train$num_videos %in% c(31:60), "31-60",
ifelse(df_train$num_videos %in% c(61:90), "61-90","Null")))
df_train$videos_range <- ordered(as.factor(df_train$videos_range),
levels = c("0-30","31-60","61-90"))
df_train$day <- ifelse(df_train$monday == 1, "Monday",
ifelse(df_train$tuesday == 1, "Tuesday",
ifelse(df_train$wednesday == 1, "Wednesday",
ifelse(df_train$thursday == 1, "Thursday",
ifelse(df_train$friday == 1, "Friday",
ifelse(df_train$saturday == 1, "Saturday",
ifelse(df_train$sunday == 1, "Sunday","Null")))))))
df_train$day <- ordered(as.factor(df_train$day),
levels = c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"))
contingency_table <- table(df_train$day,df_train$videos_range)
contingency_table
# Creating new Categorical Variables
df_train$videos_range <- ifelse(df_train$num_videos %in% c(0:30), "0-30",
ifelse(df_train$num_videos %in% c(31:60), "31-60",
ifelse(df_train$num_videos %in% c(61:90), "61-90","Null")))
df_train$videos_range <- ordered(as.factor(df_train$videos_range),
levels = c("0-30","31-60","61-90"))
df_train$day <- ifelse(df_train$monday == 1, "Monday",
ifelse(df_train$tuesday == 1, "Tuesday",
ifelse(df_train$wednesday == 1, "Wednesday",
ifelse(df_train$thursday == 1, "Thursday",
ifelse(df_train$friday == 1, "Friday",
ifelse(df_train$saturday == 1, "Saturday",
ifelse(df_train$sunday == 1, "Sunday","Null")))))))
df_train$day <- ordered(as.factor(df_train$day),
levels = c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"))
contingency_table <- table(df_train$day,df_train$videos_range)
contingency_table%>%
kbl(caption="Table for Days and Number of Images") %>%
kable_classic(full_width = F)
install.packages("kableExtra")
# Creating new Categorical Variables
df_train$videos_range <- ifelse(df_train$num_videos %in% c(0:30), "0-30",
ifelse(df_train$num_videos %in% c(31:60), "31-60",
ifelse(df_train$num_videos %in% c(61:90), "61-90","Null")))
df_train$videos_range <- ordered(as.factor(df_train$videos_range),
levels = c("0-30","31-60","61-90"))
df_train$day <- ifelse(df_train$monday == 1, "Monday",
ifelse(df_train$tuesday == 1, "Tuesday",
ifelse(df_train$wednesday == 1, "Wednesday",
ifelse(df_train$thursday == 1, "Thursday",
ifelse(df_train$friday == 1, "Friday",
ifelse(df_train$saturday == 1, "Saturday",
ifelse(df_train$sunday == 1, "Sunday","Null")))))))
df_train$day <- ordered(as.factor(df_train$day),
levels = c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"))
contingency_table <- table(df_train$day,df_train$videos_range)
contingency_table%>%
kbl(caption="Table for Days and Number of Images") %>%
kable_classic(full_width = F)
library(tidyverse)
library(caret)
library(corrplot)
library(corrr)
library(psych)
library(rmarkdown)
library(kableExtra)
# Creating new Categorical Variables
df_train$videos_range <- ifelse(df_train$num_videos %in% c(0:30), "0-30",
ifelse(df_train$num_videos %in% c(31:60), "31-60",
ifelse(df_train$num_videos %in% c(61:90), "61-90","Null")))
df_train$videos_range <- ordered(as.factor(df_train$videos_range),
levels = c("0-30","31-60","61-90"))
df_train$day <- ifelse(df_train$monday == 1, "Monday",
ifelse(df_train$tuesday == 1, "Tuesday",
ifelse(df_train$wednesday == 1, "Wednesday",
ifelse(df_train$thursday == 1, "Thursday",
ifelse(df_train$friday == 1, "Friday",
ifelse(df_train$saturday == 1, "Saturday",
ifelse(df_train$sunday == 1, "Sunday","Null")))))))
df_train$day <- ordered(as.factor(df_train$day),
levels = c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"))
contingency_table <- table(df_train$day,df_train$videos_range)
contingency_table%>%
kbl(caption="Table for Days and Number of Images") %>%
kable_classic(full_width = F)
# Creating new Categorical Variables
df_train$videos_range <- ifelse(df_train$num_videos %in% c(0:30), "0-30",
ifelse(df_train$num_videos %in% c(31:60), "31-60",
ifelse(df_train$num_videos %in% c(61:90), "61-90","Null")))
df_train$videos_range <- ordered(as.factor(df_train$videos_range),
levels = c("0-30","31-60","61-90"))
df_train$day <- ifelse(df_train$monday == 1, "Monday",
ifelse(df_train$tuesday == 1, "Tuesday",
ifelse(df_train$wednesday == 1, "Wednesday",
ifelse(df_train$thursday == 1, "Thursday",
ifelse(df_train$friday == 1, "Friday",
ifelse(df_train$saturday == 1, "Saturday",
ifelse(df_train$sunday == 1, "Sunday","Null")))))))
df_train$day <- ordered(as.factor(df_train$day),
levels = c("Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"))
contingency_table <- table(df_train$day,df_train$videos_range)
contingency_table%>%
kbl(caption="Table for Days and Number of Images") %>%
kable_classic(full_width = F)
ggplot(train_df, aes(avg_positive_polarity,log_shares))+
geom_point(aes(color=popularity)) +
geom_smooth(method="lm",color='black')+
labs(x="Average positive polarity",y="Log Number of shares")
ggplot(df_train, aes(avg_positive_polarity,log_shares))+
geom_point(aes(color=popularity)) +
geom_smooth(method="lm",color='black')+
labs(x="Average positive polarity",y="Log Number of shares")
data_plot_3 <- df_train %>%
select(n_tokens_title, shares) %>%
group_by(n_tokens_title) %>%
summarise(mean_token_title = mean(shares))
data_plot_3 <- df_train %>%
select(n_tokens_title, log_shares) %>%
group_by(n_tokens_title) %>%
summarise(mean_token_title = mean(log_shares))
ggplot(data_plot_3, aes(n_tokens_title, mean_token_title)) +
geom_line() +
labs(x="Number of words in the title",y="Average number of shares")
summarise(mean_token_title = mean(exp(log_shares))
data_plot_3 <- df_train %>%
data_plot_3 <- df_train %>%
select(n_tokens_title, exp(log_shares)) %>%
group_by(n_tokens_title) %>%
summarise(mean_token_title = mean(exp(log_shares)))
train_df$popularity <-qcut(train_df$shares,
cuts=5,
label=c('Low','Average','Good','High','Very High'))
install.packages("timereg")
library(tidyverse)
library(caret)
library(corrplot)
library(corrr)
library(psych)
library(rmarkdown)
library(kableExtra)
library(timereg)
train_df$popularity <-qcut(train_df$shares,
cuts=5,
label=c('Low','Average','Good','High','Very High'))
train_df$popularity <-qcut(df_train$shares,
cuts=5,
label=c('Low','Average','Good','High','Very High'))
train_df$popularity <-qcut(df_train$log_shares,
cuts=5,
label=c('Low','Average','Good','High','Very High'))
df_train$popularity <-qcut(df_train$log_shares,
cuts=5,
label=c('Low','Average','Good','High','Very High'))
ggplot(df_train, aes(avg_positive_polarity,log(shares)))+
geom_point(aes(color=popularity)) +
geom_smooth(method="lm",color='black')+
labs(x="Average positive polarity",y="Log Number of shares")
data_plot_3 <- df_train %>%
select(n_tokens_title, log_shares) %>%
group_by(n_tokens_title) %>%
summarise(mean_token_title = mean(log_shares))
ggplot(data_plot_3, aes(n_tokens_title, mean_token_title)) +
geom_line() +
labs(x="Number of words in the title",y="Average number of shares")
df_train$popularity <-qcut(df_train$log_shares,
cuts=5,
label=c('Low','Average','Good','High','Very High'))
ggplot(df_train, aes(avg_positive_polarity,log_shares))+
geom_point(aes(color=popularity)) +
geom_smooth(method="lm",color='black')+
labs(x="Average positive polarity",y="Log Number of shares")
df_train$popularity <-qcut(df_train$log_shares,
cuts=3,
label=c('Low','Average','High'))
ggplot(df_train, aes(avg_positive_polarity,log_shares))+
geom_point(aes(color=popularity)) +
geom_smooth(method="lm",color='black')+
labs(x="Average positive polarity",y="Log Number of shares")
df_train$Popularity <-qcut(df_train$log_shares,
cuts=3,
label=c('Low','Average','High'))
ggplot(df_train, aes(avg_positive_polarity,log_shares))+
geom_point(aes(color=popularity)) +
geom_smooth(method="lm",color='black')+
labs(x="Average positive polarity",y="Log Number of shares")
df_train$Popularity <-qcut(df_train$log_shares,
cuts=3,
label=c('Low','Average','High'))
ggplot(df_train, aes(avg_positive_polarity,log_shares))+
geom_point(aes(color=popularity)) +
geom_smooth(method="lm",color='black')+
labs(x="Average positive polarity",y="Log of shares")
plot2 <- df_train %>%
select(day, log_shares) %>%
group_by(day) %>%
summarise(Avg_Shares = mean(log_shares))
ggplot(data = plot2, aes(day, Avg_Shares)) +
labs(x="Days of Week",y="Number OF Shares",title="Number of shares per day") +
geom_col(fill="green",width=0.4)+
theme(plot.title = element_text(hjust = 0.5))
plot2 <- df_train %>%
select(day, log_shares) %>%
group_by(day) %>%
summarise(Avg_Shares = mean(log_shares))
ggplot(data = plot2, aes(day, Avg_Shares)) +
labs(x="Days of Week",y="Number OF Shares",title="Average log of shares per day") +
geom_col(fill="violet",width=0.4)+
theme(plot.title = element_text(hjust = 0.5))
df_train$Popularity <-qcut(df_train$log_shares,
cuts=5,
label=c('Very Low','Low','Average','High','Very High'))
df_train$Popularity <-qcut(df_train$log_shares,
cuts=5,
label=c('Very Low','Low','Average','High','Very High'))
ggplot(df_train, aes(avg_positive_polarity,log_shares))+
geom_point(aes(color=popularity)) +
geom_smooth(method="lm",color='black')+
labs(x="Average positive polarity",y="Log of shares")
df_train$Popularity <-qcut(df_train$log_shares,
cuts=5,
label=c('Very Low','Low','Average','High','Very High'))
ggplot(df_train, aes(avg_positive_polarity,log_shares))+
geom_point(aes(color=Popularity)) +
geom_smooth(method="lm",color='black')+
labs(x="Average positive polarity",y="Log of shares")
set.seed(594)
df_boost <- df_forest
boost_fit <- train(log_shares ~ .,data = df_boost,
method = 'gbm',
preProcess = c("center", "scale"),
trControl = tr_ctrl,
verbose = FALSE)
set.seed(111)
tr_ctrl <- trainControl(method = "repeatedcv")
lm_forward_fit <- train(shares ~ ., data = df_PC,
preProcess = c("center", "scale"),
method = "leapForward",
tuneGrid = expand.grid(nvmax = seq(1,42,2)),
trControl = tr_ctrl)
set.seed(111)
tr_ctrl <- trainControl(method = "repeatedcv")
lm_forward_fit <- train(log_shares ~ ., data = df_PC,
preProcess = c("center", "scale"),
method = "leapForward",
tuneGrid = expand.grid(nvmax = seq(1,42,2)),
trControl = tr_ctrl)
set.seed(594)
df_boost <- df_forest
boost_fit <- train(log_shares ~ .,data = df_boost,
method = 'gbm',
preProcess = c("center", "scale"),
trControl = tr_ctrl,
verbose = FALSE)
set.seed(111)
df_boost <- df_forest
boost_fit <- train(log_shares ~ .,data = df_boost,
method = 'gbm',
preProcess = c("center", "scale"),
trControl = tr_ctrl,
verbose = FALSE)
rmarkdown::render(input = "Project-3-Group-A.Rmd",output_file = "README.md")
