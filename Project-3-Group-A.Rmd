---
title: "Project-3-Group-A"
author: "Brant Armstrong, Naman Goel"
date: "2022-11-06"
output: html_document
---
# Necessary Packages
```{r, message = FALSE}
library(tidyverse)
library(caret)
library(corrplot)
library(corrr)
library(psych)
library(rmarkdown)
```
# Introduction

You should have an introduction section that briefly describes the data and the variables you have to work
with (just discuss the ones you want to use). Your target variables is the shares variable.
You should also mention the purpose of your analysis and the methods you’ll use to model the response.
You’ll describe those in more detail later.
This section should be done by the ‘second’ group member.

# Reading in Data
Need to decide on what variables we will use to predict log_shares. Some ideas below:
1. num_imgs: Number of images
2. n_tokens_content: Number of words in the content
3. n_unique_tokens: Rate of unique words in the content
4. rate_positive_words: Rate of positive words among non-neutral tokens
5. rate_negative_words: Rate of negative words among non-neutral tokens
6. Discrete variables for each day
7. num_videos: Number of videos
8. num_hrefs: Number of links
9. kw_avg_avg: Avg. keyword (avg. shares)
10. n_tokens_title: Number of words in the title

```{r}
df <- read_csv("./OnlineNewsPopularity.csv")
#Creating a new variable for to contain data channels and removing the old one.
df <- df %>%
  mutate(data_channel = if_else(
    data_channel_is_bus == 1,
    "Business",
    if_else(
      data_channel_is_entertainment == 1,
      "Entertainment",
      if_else(
        data_channel_is_lifestyle == 1,
        "Lifestyle",
        if_else(
          data_channel_is_socmed == 1,
          "Socmed",
          if_else(data_channel_is_tech == 1, "Tech", "World")))))) %>% 
  #Removing non-predictors and old data channel variables
  select(-c(url, timedelta, data_channel_is_bus, data_channel_is_entertainment,
            data_channel_is_socmed, data_channel_is_tech, data_channel_is_world,
            data_channel_is_lifestyle)) %>%
  #Changing shares to log(shares) for better graphing and models
  mutate(log_shares = log(shares)) %>%
  select(-shares) %>%
  #Renaming the day variables
  rename(monday = weekday_is_monday , tuesday = weekday_is_tuesday, wednesday = weekday_is_wednesday,          thursday = weekday_is_thursday, friday = weekday_is_friday, saturday = weekday_is_saturday,           sunday = weekday_is_sunday)
  
#Subsetting to just a single data_channel type
df_filtered <- df %>%
                filter(data_channel == "Lifestyle") 
#Creating the training and test datasets
index_train <- createDataPartition(df_filtered$log_shares, p = .7, list = FALSE )
df_train <- df_filtered[index_train,]
df_test <- df_filtered[-index_train,]

#Creating a data frame containing a categorical day variable for graphs
categ_day <- df_train %>%
  mutate(day = if_else(
    monday == 1,
    "Monday",
    if_else(
      tuesday == 1,
      "Tuesday",
      if_else(
        wednesday == 1,
        "Wednesday",
        if_else(
          thursday == 1,
          "Thursday",
          if_else(
            friday == 1,
            "Friday",
            if_else(saturday == 1,
                    "Saturday", "Sunday")))))))

#Removing variables that aren't continuous for tables and principal components
df_continuous <- df_train %>%
  select(-c(monday, tuesday, wednesday, thursday,friday, saturday, sunday, is_weekend, data_channel,
            n_non_stop_words))
```

# Summarization

Creating a boxplot of log_shares by newly created `Day` variable.
```{r}
#Box plot of log_shares by day
ggplot(categ_day, aes(x = day, y = log_shares, col = day)) + 
  geom_boxplot(fill="grey") + 
  geom_jitter() + 
  ylab("Log Shares") + 
  xlab("") +
  theme(axis.text.x = element_text(angle = 45)) +
  ggtitle("Boxplot for Log Shares by Day")
```

Here are a bunch of quick scatter plots for variables of interest that can be modified to be used in the project
```{r}
ggplot(categ_day, aes(y = log_shares, x = num_hrefs, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("num_hrefs") + 
  ylab("log_shares")

ggplot(categ_day, aes(y = log_shares, x = num_videos, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("num_videos") + 
  ylab("log_shares")

ggplot(categ_day, aes(y = log_shares, x = num_imgs, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("num_imgs") + 
  ylab("log_shares")

ggplot(categ_day, aes(y = log_shares, x = rate_negative_words, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("rate_negative_words") + 
  ylab("log_shares")

ggplot(categ_day, aes(y = log_shares, x = rate_positive_words, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("rate_positive_words") + 
  ylab("log_shares")

ggplot(categ_day, aes(y = log_shares, x = n_unique_tokens, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("n_unique_tokens") + 
  ylab("log_shares")

ggplot(categ_day, aes(y = log_shares, x = n_tokens_content, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("n_tokens_content") + 
  ylab("log_shares")

ggplot(categ_day, aes(y = log_shares, x = kw_avg_avg, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("kw_avg_avg") + 
  ylab("log_shares")

ggplot(categ_day, aes(y = log_shares, x = n_tokens_title, color = day)) + 
  geom_point(stat = "identity", position = "jitter") + 
  geom_smooth( method = "lm")  + 
  xlab("n_tokens_title") + 
  ylab("log_shares")
```

This is the above scatterplots in a facet wrap. They come out pretty small
```{r}
interest_vars <- c("num_imgs", "n_tokens_content", "n_unique_tokens", "rate_positive_words",
                   "rate_negative_words", "num_videos", "num_hrefs", "kw_avg_avg", "n_tokens_title")
categ_day %>%
  gather(interest_vars, key = "variables", value = "value") %>%
  ggplot(aes(x = value, y = log_shares, color = day)) +
    geom_point() +
    stat_smooth(method = "lm") +
    facet_wrap(~ variables, scales = "free", shrink = FALSE, ncol=2  ) +
    theme_bw()
```

Calculating the correlation of each predictor variable with the outcome variable `shares` and graphing it.
```{r}
cor_train<- df_train %>%
  correlate() %>%
  focus(log_shares)
paged_table(cor_train)

#Graph of the correlations but it's pretty messy. Might be a way to automate only including the top 10 correlated variables to use later
cor_train %>% 
  mutate(term = factor(term, levels = term[order(log_shares)])) %>%  # Order by correlation strength
  ggplot(aes(x = term, y = log_shares)) +
    geom_bar(stat = "identity") +
    ylab("Correlation with log(Shares)") +
    xlab("Variable") +
  theme(axis.text.x = element_text(angle = 90)) 
```

Summary statistics using the `describe` function from the `psych` package sorted by standard deviation.
```{r}
tab <-  describe(df_continuous, fast = TRUE)
#Arranging by Standard Deviation and rounding to two places
table_continuous <- tab %>%
  arrange(desc(sd)) %>%
  modify_if( ~is.numeric(.), ~round(.,2))
#Paged table to allow reader to peruse all variables
paged_table(table_continuous)
```

Principal Components
```{r}
#Excluding shares for creating principal components
df_no_shares <- df_continuous %>%
  select(-log_shares)
#Creating PC's along with center and scaling variables
PCs <- prcomp(df_no_shares, center = TRUE, scale = TRUE)
#Creating screeplots
par(mfrow = c(1,2))
plot(PCs$sdev^2/sum(PCs$sdev^2), xlab = "Principal Component",
ylab = "Proportion of Variance Explained", ylim = c(0, 1), type = 'b')
plot(cumsum(PCs$sdev^2/sum(PCs$sdev^2)), xlab = "Principal Component",
ylab = "Cum. Prop of Variance Explained", ylim = c(0, 1), type = 'b')
#Selecting only the PC's up to a 80% variance explained threshold using caret
PCs_eighty <- preProcess(df_no_shares, method = c("center","scale", "pca"), thresh = .8)
#Creating a data frame with just my PC's, day variables, and log_shares to use later as a regression
df_PC <- predict(PCs_eighty, newdata = df_no_shares)
#Monday is excluded to avoid multicollinearity
df_PC <- df_PC %>%
  bind_cols(log_shares = df_continuous$log_shares,tuesday = df_train$tuesday, 
            wednesday = df_train$wednesday, thursday = df_train$thursday, friday = df_train$friday,
            saturday = df_train$saturday, sunday = df_train$sunday)

```

Principal Components Regression
```{r}
set.seed(111)
fit_PC <- train(log_shares ~ ., data = df_PC, 
                 method = "lm",
                 trControl = trainControl(method = "cv" , number = 10))
summary(fit_PC)
#Creating a test data frame from the PCs then using that to test the PC regression. RMSE reported after.
test_PC <- predict(PCs_eighty, newdata = df_test)
pred_PC <- predict(fit_PC, newdata = test_PC)
postResample(pred_PC, obs = df_test$log_shares)
```

Random Forest
```{r}
forest_vars <- c("log_shares","num_imgs", "n_tokens_content", "n_unique_tokens", "rate_positive_words",
                   "rate_negative_words", "num_videos", "num_hrefs", "kw_avg_avg", "n_tokens_title",
                   "tuesday", "wednesday","thursday","friday", "saturday", "sunday", "monday")
df_forest <- df_train %>%
  select(forest_vars)
set.seed(111)
fit_forest <- train(log_shares ~ ., data = df_forest, method = "treebag",
                 trControl = trainControl(method = "cv" , number = 10),
                 preProcess = c("center", "scale"),
                 mtry = c(1:17))
pred_forest <- predict(fit_forest, newdata = df_test)
postResample(pred_forest, df_test$log_shares)
```

